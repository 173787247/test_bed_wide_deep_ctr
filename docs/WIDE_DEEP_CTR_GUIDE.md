# Wide & Deep CTR模型使用指南

## 概述

系统现在支持两种CTR模型：
1. **逻辑回归 (LR)** - 经典线性模型，训练快速，解释性强
2. **Wide & Deep** - 结合线性模型和深度神经网络，效果更好

## 功能特点

### 🔄 模型选择
- 在训练标签页中可以选择不同的CTR模型类型
- 支持模型类型切换，无需重启系统
- 每种模型都有独立的保存和加载机制

### 🧠 Wide & Deep模型优势
- **Wide部分**: 处理记忆化特征，学习特征交叉
- **Deep部分**: 处理泛化特征，学习复杂模式
- **嵌入层**: 处理分类特征，降低维度
- **更好的预测效果**: 通常比单一LR模型效果更好

## 模型架构

### Wide & Deep架构详解

```
输入特征
    ├── Wide特征 (线性特征)
    │   ├── 位置特征
    │   ├── 位置衰减
    │   ├── 相似度分数
    │   ├── 查询匹配度
    │   └── 历史CTR特征
    │
    ├── Deep特征 (非线性特征)
    │   ├── 数值特征
    │   │   ├── 长度特征
    │   │   ├── 词数量特征
    │   │   └── 时间特征
    │   └── 交叉特征
    │       ├── 位置×分数
    │       └── 查询长度×匹配度
    │
    └── 嵌入特征 (分类特征)
        ├── 查询哈希嵌入 (8维)
        ├── 文档哈希嵌入 (8维)
        └── 位置分组嵌入 (4维)

网络结构
    ├── Wide部分: 直接连接到输出
    └── Deep部分: 嵌入层 → 全连接层(128) → 全连接层(64) → 全连接层(32)
                                ↓
                            合并层
                                ↓
                            输出层 (Sigmoid)
```

## 使用方法

### 1. 训练模型

1. 进入 **"📊 第三部分：数据回收训练"** 标签页
2. 在 **"🎯 模型选择"** 区域选择CTR模型类型：
   - **逻辑回归 (LR)** - 适合快速训练和测试
   - **Wide & Deep** - 适合追求更好效果
3. 点击 **"🚀 开始训练"** 按钮
4. 等待训练完成，查看训练结果

### 2. 查看训练结果

训练完成后会显示：
- **模型类型**: 当前使用的模型类型
- **性能指标**: AUC、准确率、精确率、召回率、F1分数
- **样本信息**: 训练样本数和测试样本数
- **特征重要性**: 特征的重要性排序

### 3. 模型选择建议

#### 使用逻辑回归 (LR) 的场景：
- 数据量较小 (< 1000条)
- 需要快速训练和测试
- 对模型解释性要求高
- 计算资源有限

#### 使用Wide & Deep的场景：
- 数据量较大 (> 1000条)
- 追求更好的预测效果
- 有充足的计算资源
- 不需要强解释性

## 技术实现

### 模型配置

模型配置在 `ctr_config.py` 中定义：

```python
SUPPORTED_MODELS = {
    'logistic_regression': {
        'name': '逻辑回归 (LR)',
        'description': '经典线性模型，训练快速，解释性强',
        'class': 'CTRModel',
        'module': '.ctr_model'
    },
    'wide_and_deep': {
        'name': 'Wide & Deep',
        'description': '结合线性模型和深度神经网络，效果更好',
        'class': 'WideAndDeepCTRModel',
        'module': '.ctr_wide_deep_model'
    }
}
```

### 特征工程

#### Wide特征 (线性特征)
- 位置特征、位置衰减
- 相似度分数
- 查询匹配度
- 历史CTR特征

#### Deep特征 (非线性特征)
- 长度特征 (文档、查询、摘要长度)
- 词数量特征
- 时间特征
- 交叉特征

#### 嵌入特征 (分类特征)
- 查询哈希 → 8维嵌入
- 文档哈希 → 8维嵌入
- 位置分组 → 4维嵌入

### 模型训练参数

```python
# Wide & Deep训练参数
epochs = 20                    # 训练轮数
batch_size = 32               # 批次大小
learning_rate = 0.001         # 学习率
dropout_rate = 0.2            # Dropout率
early_stopping_patience = 5   # 早停耐心值
```

## 依赖要求

### 必需依赖
```
tensorflow>=2.13.0    # TensorFlow核心
keras>=2.13.0         # Keras神经网络
numpy>=1.21.0         # 数值计算
pandas>=1.5.0         # 数据处理
scikit-learn>=1.2.0   # 机器学习工具
```

### 安装命令
```bash
pip install tensorflow>=2.13.0 keras>=2.13.0
```

## 性能对比

### 典型性能差异
| 指标 | 逻辑回归 (LR) | Wide & Deep |
|------|---------------|-------------|
| 训练速度 | 快 (秒级) | 慢 (分钟级) |
| 预测效果 | 良好 | 更好 |
| 内存占用 | 低 | 高 |
| 解释性 | 高 | 低 |
| 过拟合风险 | 低 | 中等 |

### 实验建议
1. 先用LR模型快速验证数据质量（门槛：10条数据）
2. 数据质量确认后使用Wide & Deep追求更好效果（门槛：同样10条数据）
3. 对比两种模型的实际效果差异
4. 根据业务需求和数据规模选择合适的模型

## 故障排除

### 常见问题

#### 1. TensorFlow未安装
**错误**: "TensorFlow未安装，Wide & Deep模型将不可用"
**解决**: 运行 `pip install tensorflow>=2.13.0`

#### 2. 训练失败
**可能原因**: 数据量不足、特征质量差、内存不足
**解决**: 
- 确保至少有100条训练数据
- 检查数据质量
- 增加系统内存

#### 3. 训练时间过长
**原因**: Wide & Deep模型复杂度高
**解决**:
- 减少训练轮数 (epochs)
- 增加批次大小 (batch_size)
- 使用更小的网络结构

#### 4. 效果不如预期
**原因**: 数据量不足、特征工程不合适
**解决**:
- 收集更多训练数据
- 调整特征工程逻辑
- 尝试不同的网络结构

## 最佳实践

### 1. 数据准备
- 最少需要10条训练数据（与LR模型一致）
- 建议至少100条数据以获得更好效果
- 保证点击率在1%-50%之间
- 确保查询和文档的多样性

### 2. 模型选择
- 根据实际需求选择合适的模型类型
- 可以同时尝试两种模型并比较效果
- 考虑训练时间、预测效果、资源消耗等因素

### 3. 性能优化
- 定期重新训练模型
- 监控模型效果变化
- 根据业务反馈调整特征

### 4. 生产部署
- 先在测试环境验证模型效果
- 逐步切换到新模型
- 保留模型回退机制

## 扩展功能

### 未来可能的改进
1. **更多模型类型**: 增加XGBoost、CatBoost等模型
2. **自动超参数优化**: 使用Optuna等工具优化参数
3. **模型集成**: 组合多个模型的预测结果
4. **在线学习**: 支持模型的增量更新
5. **A/B测试**: 支持多个模型同时运行对比

### 自定义模型
如需添加新的CTR模型类型：
1. 在 `ctr_config.py` 中添加模型配置
2. 实现对应的模型类
3. 在 `training_tab.py` 中添加模型创建逻辑
4. 更新UI选择列表

## 注意事项

1. **计算资源**: Wide & Deep模型需要更多CPU/内存资源
2. **训练时间**: 深度学习模型训练时间较长，请耐心等待
3. **模型文件**: 不同类型的模型使用不同的保存格式
4. **兼容性**: 确保TensorFlow版本兼容性
5. **数据质量**: 模型效果高度依赖训练数据质量

## 总结

Wide & Deep CTR模型为系统提供了更强大的点击率预测能力，通过结合线性模型的记忆能力和深度网络的泛化能力，能够在复杂的搜索场景中取得更好的效果。根据实际业务需求和数据规模，合理选择模型类型，是提升搜索质量的重要手段。
